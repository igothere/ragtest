# 요구사항 문서

## 개요

현재 RAG 시스템에서 SentenceTransformer 모델("nlpai-lab/KURE-v1")이 api_server.py와 rag_with_tables.py 두 파일에서 각각 독립적으로 로딩되고 있습니다. 이로 인해 메모리 사용량이 증가하고 초기화 시간이 길어지는 문제가 발생하고 있습니다. 모델을 한 번만 로딩하여 공유할 수 있는 구조로 개선이 필요합니다.

## 요구사항

### 요구사항 1

**사용자 스토리:** 시스템 관리자로서, SentenceTransformer 모델이 한 번만 로딩되어 여러 프로세스에서 공유되기를 원합니다. 이를 통해 메모리 사용량을 최적화하고 시작 시간을 단축하고자 합니다.

#### 승인 기준

1. 시스템이 시작될 때 SentenceTransformer 모델은 한 번만 로딩되어야 합니다
2. api_server.py가 모델이 필요할 때 공유된 모델 인스턴스에 접근해야 합니다
3. rag_with_tables.py가 모델이 필요할 때 동일한 공유 모델 인스턴스에 접근해야 합니다
4. 여러 프로세스가 동시에 모델에 접근할 때 시스템은 동시 접근을 안전하게 처리해야 합니다

### 요구사항 2

**사용자 스토리:** 개발자로서, 중앙화된 모델 관리 시스템을 원합니다. 이를 통해 모델 로딩 로직이 애플리케이션 전반에 걸쳐 일관되고 유지보수 가능하도록 하고자 합니다.

#### 승인 기준

1. 새로운 스크립트가 모델이 필요할 때 중앙화된 모델 매니저를 사용해야 합니다
2. 모델을 업데이트하거나 변경해야 할 때 하나의 설정 지점만 수정하면 됩니다
3. 시스템이 초기화될 때 모델 매니저는 모델 로딩 상태에 대한 명확한 로깅을 제공해야 합니다
4. 모델 로딩이 실패할 경우 시스템은 적절한 에러 처리와 폴백 메커니즘을 제공해야 합니다

### 요구사항 3

**사용자 스토리:** 시스템 사용자로서, RAG 시스템의 응답 시간이 더 빨라지기를 원합니다. 이를 통해 문서 처리와 쿼리 응답이 더 효율적이 되기를 바랍니다.

#### 승인 기준

1. 시스템이 시작될 때 현재 구현 대비 전체 메모리 사용량이 감소해야 합니다
2. 여러 파일을 동시에 처리할 때 시스템은 중복된 모델 인스턴스를 로딩하지 않아야 합니다
3. API 서버가 채팅 요청을 처리할 때 추가적인 로딩 시간 없이 미리 로딩된 모델을 사용해야 합니다
4. rag_with_tables.py가 문서를 처리할 때 공유 모델 접근으로 인해 더 빠르게 완료되어야 합니다

### 요구사항 4

**사용자 스토리:** 개발자로서, 모델 공유 솔루션이 하위 호환성을 유지하기를 원합니다. 이를 통해 기존 기능이 중단 없이 계속 작동하기를 바랍니다.

#### 승인 기준

1. 새로운 모델 공유 시스템이 구현될 때 모든 기존 API 엔드포인트가 계속 작동해야 합니다
2. 문서 처리가 수행될 때 출력 형식과 품질이 변경되지 않아야 합니다
3. 채팅 기능을 사용할 때 응답 정확도와 형식이 유지되어야 합니다
4. 공유 모델 시스템이 실패할 경우 시스템은 개별 모델 로딩으로 우아하게 폴백해야 합니다