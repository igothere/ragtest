# api_server.py

import os
import subprocess
import uuid # uuid ì„í¬íŠ¸
from flask import Flask, request, jsonify
from flask_cors import CORS
import requests # API í˜¸ì¶œì„ ìœ„í•´ ì¶”ê°€
import psycopg2
from sentence_transformers import SentenceTransformer
from rag import normalize_text 
# from werkzeug.utils import secure_filename

# ì„¤ì •
UPLOAD_FOLDER = "./docs"
ALLOWED_EXTENSIONS = {'txt', 'pdf', 'md'}
PROCESSING_SCRIPT = 'rag.py'

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
CORS(app)

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({"error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"}), 400
    
    file = request.files['file']
    
    if file.filename == '':
        return jsonify({"error": "íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 400
        
    if file and allowed_file(file.filename):
        # original_filename = secure_filename(file.filename)
        original_filename = file.filename
        
        # ê³ ìœ  íŒŒì¼ëª… ìƒì„± (uuid + í™•ì¥ì)
        file_ext = original_filename.rsplit('.', 1)[1].lower()
        unique_filename = f"{uuid.uuid4()}.{file_ext}"
        
        save_path = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
        
        try:
            # 1. íŒŒì¼ì„ ê³ ìœ í•œ ì´ë¦„ìœ¼ë¡œ ë””ë ‰í† ë¦¬ì— ì €ì¥
            file.save(save_path)
            print(f"âœ… íŒŒì¼ ì €ì¥ ì„±ê³µ: {save_path} (ì›ë³¸: {original_filename})")

            # 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            env = os.environ.copy()
            env['OLLAMA_ENDPOINT'] = "https://api.hamonize.com/ollama/api/chat"
            env['OLLAMA_MODEL'] = "airun-chat:latest"
            env['USE_SUMMARIZATION_CHUNKING'] = "true"

            # 3. rag.py ìŠ¤í¬ë¦½íŠ¸ì— ê³ ìœ  íŒŒì¼ëª…ê³¼ ì›ë³¸ íŒŒì¼ëª…ì„ ëª¨ë‘ ì „ë‹¬
            print(f"ğŸš€ {PROCESSING_SCRIPT} ì‹¤í–‰í•˜ì—¬ {unique_filename} ì²˜ë¦¬ ì‹œì‘...")
            
            # ê°€ìƒí™˜ê²½ì˜ python ê²½ë¡œ ì‚¬ìš©
            python_path = os.path.join(os.getcwd(), 'venv', 'bin', 'python')
            if not os.path.exists(python_path):
                python_path = 'python'  # ê°€ìƒí™˜ê²½ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ python ì‚¬ìš©
            
            # í‘œ ì²˜ë¦¬ RAG ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
            table_script = 'rag_with_tables.py'
            if os.path.exists(table_script):
                script_to_use = table_script
                print(f"  ğŸ“Š í‘œ ì²˜ë¦¬ RAG ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©: {script_to_use}")
            else:
                script_to_use = PROCESSING_SCRIPT
                print(f"  ğŸ“ ê¸°ë³¸ RAG ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©: {script_to_use}")
            
            result = subprocess.run(
                [python_path, script_to_use, unique_filename, original_filename], # ì¸ì 2ê°œ ì „ë‹¬
                capture_output=True,
                text=True,
                check=True,
                env=env,  # í™˜ê²½ë³€ìˆ˜ ì „ë‹¬
                cwd=os.getcwd()  # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
            )
            
            print(f"ğŸ“œ ìŠ¤í¬ë¦½íŠ¸ ì¶œë ¥:\n{result.stdout}")
            return jsonify({"message": f"'{original_filename}' íŒŒì¼ ì²˜ë¦¬ ì„±ê³µ", "output": result.stdout}), 200

        except subprocess.CalledProcessError as e:
            print(f"âŒ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì˜¤ë¥˜:")
            print(f"   ë°˜í™˜ ì½”ë“œ: {e.returncode}")
            print(f"   í‘œì¤€ ì¶œë ¥: {e.stdout}")
            print(f"   í‘œì¤€ ì—ëŸ¬: {e.stderr}")
            return jsonify({
                "error": "íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", 
                "details": e.stderr,
                "stdout": e.stdout,
                "returncode": e.returncode
            }), 500
        except Exception as e:
            print(f"âŒ ì„œë²„ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return jsonify({"error": str(e)}), 500
            
    return jsonify({"error": "í—ˆìš©ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤"}), 400
  
  # --- ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ê³¼ DB ì„¤ì •ì„ ë¯¸ë¦¬ ì¤€ë¹„ ---
print("ğŸ¤– RAG ê²€ìƒ‰ìš© ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
try:
    model = SentenceTransformer("nlpai-lab/KURE-v1")
    print("âœ… ê²€ìƒ‰ìš© ëª¨ë¸ ë¡œë”© ì™„ë£Œ.")
except Exception as e:
    print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    model = None

DB_CONFIG = {
    "host": "localhost", "port": "5432", "dbname": "ragtest",
    "user": "eden", "password": "qwer123"
}

# --- Ollama ì„¤ì • ì¶”ê°€ ---
OLLAMA_ENDPOINT = "https://api.hamonize.com/ollama/api/chat"
OLLAMA_MODEL = "airun-chat:latest" # ì‚¬ìš©í•˜ë ¤ëŠ” Ollama ëª¨ë¸ëª…
# -------------------------

# ê¸°ì¡´ ask_question ë˜ëŠ” chat í•¨ìˆ˜ë¥¼ ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.
@app.route('/chat', methods=['POST'])
def chat_with_doc():
    if not model:
        return jsonify({"error": "ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500

    data = request.get_json()
    if not data or 'question' not in data:
        return jsonify({"error": "ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

    original_question = data['question']
    print(f"ğŸ” ìˆ˜ì‹ ëœ ì§ˆë¬¸: {original_question}")
    
    # ì§ˆë¬¸ë„ ë¬¸ì„œì™€ ë™ì¼í•˜ê²Œ ì •ê·œí™”í•©ë‹ˆë‹¤.
    normalized_question = normalize_text(original_question)
    print(f"ğŸ” ì •ê·œí™”ëœ ì§ˆë¬¸: {normalized_question}")

    try:
        # 1. ì§ˆë¬¸ ë²¡í„°í™” ë° ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
        print("  - 1. ì§ˆë¬¸ ë²¡í„°í™” ë° ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
        question_embedding = model.encode(normalized_question).tolist()
        embedding_str = "[" + ",".join(map(str, question_embedding)) + "]"

        conn = psycopg2.connect(**DB_CONFIG)
        cur = conn.cursor()
        # id, ì›ë³¸ íŒŒì¼ëª…, ì²­í¬ ë²ˆí˜¸, ìœ ì‚¬ë„ë„ í•¨ê»˜ ê°€ì ¸ì˜¤ë„ë¡ SQL ìˆ˜ì •
        sql = """
            SELECT 
                id, 
                content, 
                original_filename, 
                chunk_index,
                1 - (embedding <=> %s::vector) AS similarity
            FROM documents
            ORDER BY embedding <=> %s::vector
            LIMIT 5;
        """
        cur.execute(sql, (embedding_str, embedding_str))
        results = cur.fetchall()
        cur.close()
        conn.close()

        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë‚˜ì¤‘ì— ë°˜í™˜í•˜ê¸° ìœ„í•´ ì €ì¥
        sources = [
            {
                "id": row[0],
                "content": row[1],
                "filename": row[2],
                "chunk": row[3],
                "similarity": f"{row[4]:.4f}"
            }
            for row in results
        ]

        if not sources:
            return jsonify({"answer": "ê´€ë ¨ëœ ì •ë³´ë¥¼ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "sources": []})

        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„±
        print("  - 2. AI í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        context = "\n\n".join([source['content'] for source in sources])
        
        prompt = f"""
        You are an AI assistant that provides accurate and reliable answers to user questions, primarily by referring to the given 'document content.'
You should actively use the 'document content' when answering, but you may also utilize external knowledge or web information if necessary.
All answers must be written in Korean.

        --- ë¬¸ì„œ ë‚´ìš© ---
        {context}
        -----------------

        --- ì§ˆë¬¸ ---
        {normalized_question}
        ------------

        ë‹µë³€:
        """

        # 3. Ollama API í˜¸ì¶œ
        print(f"  - 3. Ollama API ({OLLAMA_MODEL}) í˜¸ì¶œ ì¤‘...")
        ollama_payload = {
            "model": OLLAMA_MODEL,
            "messages": [{"role": "user", "content": prompt}],
            "stream": False
        }
        
        response = requests.post(OLLAMA_ENDPOINT, json=ollama_payload, timeout=120)
        response.raise_for_status()
        
        response_data = response.json()
        answer = response_data['message']['content']
        
        print("  - 4. AI ë‹µë³€ ìˆ˜ì‹  ì™„ë£Œ.")
        
        # 4. ìµœì¢… ë‹µë³€ê³¼ ê·¼ê±° ë¬¸ì„œë¥¼ í•¨ê»˜ ë°˜í™˜
        return jsonify({"answer": answer, "sources": sources})

    except requests.exceptions.RequestException as e:
        print(f"âŒ Ollama API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return jsonify({"error": "AI ëª¨ë¸ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 500
    except Exception as e:
        print(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": "ë‹µë³€ ìƒì„± ì¤‘ ì„œë²„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}), 500


if __name__ == '__main__':
    if not os.path.exists(UPLOAD_FOLDER):
        os.makedirs(UPLOAD_FOLDER)
    app.run(host='0.0.0.0', port=5001, debug=True)